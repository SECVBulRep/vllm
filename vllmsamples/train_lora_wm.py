"""
–û–±—É—á–µ–Ω–∏–µ Qwen LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ Redmine Wiki
–ó–∞—Ç–µ–º –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ vLLM.

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:
  pip install torch transformers peft datasets accelerate bitsandbytes trl

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  # –û–±—É—á–µ–Ω–∏–µ
  python train_lora.py --dataset dataset.json --model Qwen/Qwen2.5-7B-Instruct

  # –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è ‚Äî –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ vLLM:
  python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-7B-Instruct \
    --enable-lora \
    --lora-modules wiki-lora=./output/qwen-wiki-lora \
    --port 8000
"""

import json
import argparse
import os
import torch
from pathlib import Path


def load_dataset_sharegpt(dataset_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç ShareGPT –¥–∞—Ç–∞—Å–µ—Ç –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è trl."""
    from datasets import Dataset

    with open(dataset_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ShareGPT ‚Üí messages —Ñ–æ—Ä–º–∞—Ç
    processed = []
    for entry in raw_data:
        convs = entry["conversations"]
        messages = []
        for msg in convs:
            role_map = {"system": "system", "human": "user", "gpt": "assistant"}
            role = role_map.get(msg["from"], msg["from"])
            messages.append({"role": role, "content": msg["value"]})
        processed.append({"messages": messages})

    dataset = Dataset.from_list(processed)
    print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(dataset)}")
    return dataset


def train(args):
    from transformers import (
        AutoModelForCausalLM,
        AutoTokenizer,
        BitsAndBytesConfig,
    )
    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType
    from trl import SFTTrainer, SFTConfig

    print(f"üîß –ú–æ–¥–µ–ª—å:   {args.model}")
    print(f"üìÑ –î–∞—Ç–∞—Å–µ—Ç:  {args.dataset}")
    print(f"üíæ –í—ã—Ö–æ–¥:    {args.output_dir}")
    print(f"üìä –≠–ø–æ—Ö–∏:    {args.epochs}")
    print(f"üìä LoRA r:   {args.lora_rank}")
    print(f"üìä Batch:    {args.batch_size}")
    print()

    # ---- –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä ----
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
    tokenizer = AutoTokenizer.from_pretrained(
        args.model,
        trust_remote_code=True,
        padding_side="right",
    )
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # ---- –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ----
    bnb_config = None
    if args.use_4bit:
        print("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (QLoRA)")
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
        )

    # ---- –ú–æ–¥–µ–ª—å ----
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = AutoModelForCausalLM.from_pretrained(
        args.model,
        quantization_config=bnb_config,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.bfloat16 if not args.use_4bit else None,
        attn_implementation="flash_attention_2" if args.flash_attn else None,
    )

    if args.use_4bit:
        model = prepare_model_for_kbit_training(model)

    model.config.use_cache = False

    # ---- LoRA ----
    print("üîó –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA...")
    lora_config = LoraConfig(
        r=args.lora_rank,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
        bias="none",
        task_type=TaskType.CAUSAL_LM,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                        "gate_proj", "up_proj", "down_proj"],
    )

    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    # ---- –î–∞—Ç–∞—Å–µ—Ç ----
    print("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    dataset = load_dataset_sharegpt(args.dataset)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/eval
    if len(dataset) > 20:
        split = dataset.train_test_split(test_size=min(0.1, 50 / len(dataset)), seed=42)
        train_dataset = split["train"]
        eval_dataset = split["test"]
        print(f"   Train: {len(train_dataset)}, Eval: {len(eval_dataset)}")
    else:
        train_dataset = dataset
        eval_dataset = None
        print(f"   Train: {len(train_dataset)}, Eval: –Ω–µ—Ç (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)")

    # ---- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è ----
    training_args = SFTConfig(
        output_dir=args.output_dir,
        num_train_epochs=args.epochs,
        per_device_train_batch_size=args.batch_size,
        gradient_accumulation_steps=args.gradient_accumulation,
        learning_rate=args.learning_rate,
        weight_decay=0.01,
        warmup_ratio=0.1,
        lr_scheduler_type="cosine",
        logging_steps=5,
        save_steps=50,
        save_total_limit=3,
        eval_strategy="steps" if eval_dataset else "no",
        eval_steps=50 if eval_dataset else None,
        bf16=True,
        gradient_checkpointing=True,
        gradient_checkpointing_kwargs={"use_reentrant": False},
        report_to="none",
        max_grad_norm=1.0,
        seed=42,
        max_seq_length=args.max_seq_length,
    )

    # ---- Trainer ----
    print("\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    trainer = SFTTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        processing_class=tokenizer,
    )

    trainer.train()

    # ---- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ----
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ –≤ {args.output_dir}...")
    trainer.save_model(args.output_dir)
    tokenizer.save_pretrained(args.output_dir)

    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"\n{'='*60}")
    print(f"üì¶ LoRA –∞–¥–∞–ø—Ç–µ—Ä: {args.output_dir}")
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ vLLM:")
    print(f"   python -m vllm.entrypoints.openai.api_server \\")
    print(f"     --model {args.model} \\")
    print(f"     --enable-lora \\")
    print(f"     --lora-modules wiki-lora={args.output_dir} \\")
    print(f"     --port 8000")
    print(f"\nüì° –ó–∞–ø—Ä–æ—Å –∫ API:")
    print(f'   curl http://localhost:8000/v1/chat/completions \\')
    print(f'     -d \'{{"model": "wiki-lora", "messages": [{{"role": "user", "content": "–ß—Ç–æ —Ç–∞–∫–æ–µ X9?"}}]}}\'')
    print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(description="–û–±—É—á–µ–Ω–∏–µ Qwen LoRA –Ω–∞ wiki –¥–∞—Ç–∞—Å–µ—Ç–µ")

    # –û—Å–Ω–æ–≤–Ω—ã–µ
    parser.add_argument("--model", default="Qwen/Qwen2.5-7B-Instruct",
                        help="–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: Qwen/Qwen2.5-7B-Instruct)")
    parser.add_argument("--dataset", default="dataset.json",
                        help="–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É")
    parser.add_argument("--output-dir", default="./output/qwen-wiki-lora",
                        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è LoRA")

    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument("--epochs", type=int, default=3,
                        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)")
    parser.add_argument("--batch-size", type=int, default=2,
                        help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2)")
    parser.add_argument("--gradient-accumulation", type=int, default=8,
                        help="Gradient accumulation steps (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 8)")
    parser.add_argument("--learning-rate", type=float, default=1e-4,
                        help="Learning rate (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1e-4)")
    parser.add_argument("--max-seq-length", type=int, default=2048,
                        help="–ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2048)")

    # LoRA
    parser.add_argument("--lora-rank", type=int, default=16,
                        help="LoRA rank (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 16)")
    parser.add_argument("--lora-alpha", type=int, default=32,
                        help="LoRA alpha (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 32)")
    parser.add_argument("--lora-dropout", type=float, default=0.05,
                        help="LoRA dropout (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.05)")

    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    parser.add_argument("--use-4bit", action="store_true",
                        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å QLoRA (4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è)")
    parser.add_argument("--flash-attn", action="store_true",
                        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Flash Attention 2")

    args = parser.parse_args()
    train(args)


if __name__ == "__main__":
    main()